#!/usr/bin/env python3
import json
import os
from pathlib import Path


def get_script_dir():
    """è·å–è„šæœ¬æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„"""
    return Path(__file__).parent.absolute()


def find_input_file():
    """ç›¸å¯¹äºè„šæœ¬ä½ç½®æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶"""
    script_dir = get_script_dir()
    print(f"ğŸ“‚ è„šæœ¬ä½ç½®: {script_dir}")

    # ç›¸å¯¹äºè„šæœ¬ä½ç½®çš„å¯èƒ½è·¯å¾„
    possible_paths = [
        script_dir / ".cache" / "gpu" / "batch_cleaning_step_step4.json",
        script_dir / "cache" / "gpu" / "batch_cleaning_step_step4.json",
        script_dir / "batch_cleaning_step_step4.json",
        script_dir.parent / ".cache" / "gpu" / "batch_cleaning_step_step4.json",  # ä¸Šçº§ç›®å½•
        script_dir / ".." / ".cache" / "gpu" / "batch_cleaning_step_step4.json",  # ç›¸å¯¹è·¯å¾„å½¢å¼
    ]

    print("ğŸ” æœç´¢è¾“å…¥æ–‡ä»¶...")
    for path in possible_paths:
        abs_path = path.resolve()  # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if abs_path.exists():
            size = abs_path.stat().st_size
            print(f"âœ… æ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {abs_path} ({size} å­—èŠ‚)")
            return abs_path
        else:
            print(f"âŒ æœªæ‰¾åˆ°: {abs_path}")

    print("âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ï¼")
    return None


def convert_to_alpaca(input_file, output_dir=None):
    """è½¬æ¢ä¸ºAlpacaæ ¼å¼"""
    script_dir = get_script_dir()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä½¿ç”¨è„šæœ¬åŒçº§çš„dataç›®å½•
    if output_dir is None:
        output_dir = script_dir / "data"
    else:
        output_dir = Path(output_dir)

    print(f"ğŸ“– è¯»å–æ•°æ®æ–‡ä»¶: {input_file}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")

    results = []

    # è¯»å–æ•°æ®
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼Œç±»å‹: {type(data)}, é•¿åº¦: {len(data) if hasattr(data, '__len__') else 'N/A'}")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return None

    # å­¦æœ¯è®ºæ–‡ä¸“ç”¨instruction
    instruction = (
        "Please answer the following question based on the provided academic literature. "
        "Your response should:\n"
        "1. Provide accurate information from the source material\n"
        "2. Include relevant scientific reasoning and methodology\n"
        "3. Reference specific findings, data, or conclusions when applicable\n"
        "4. Maintain academic rigor and precision in your explanation\n\n"
        "Focus on delivering factual, evidence-based answers suitable for academic research."
    )

    # å¤„ç†æ¯ä¸ªQAå¯¹
    processed_items = 0
    total_qa_pairs = 0

    print("ğŸ”„ å¤„ç†QAå¯¹...")

    for i, item in enumerate(data):
        print(f"å¤„ç†é¡¹ç›® {i + 1}/{len(data)}: ", end="")

        # æ£€æŸ¥æ•°æ®ç»“æ„
        if not isinstance(item, dict):
            print("è·³è¿‡ï¼ˆéå­—å…¸æ ¼å¼ï¼‰")
            continue

        if "MultiHop_QA" not in item:
            print("è·³è¿‡ï¼ˆæ— MultiHop_QAå­—æ®µï¼‰")
            # æ‰“å°å¯ç”¨å­—æ®µä¾›è°ƒè¯•
            if i == 0:  # åªæ‰“å°ç¬¬ä¸€ä¸ªçš„å­—æ®µ
                print(f"   å¯ç”¨å­—æ®µ: {list(item.keys())}")
            continue

        multihop_qa = item.get("MultiHop_QA", {})
        if not isinstance(multihop_qa, dict):
            print("è·³è¿‡ï¼ˆMultiHop_QAä¸æ˜¯å­—å…¸ï¼‰")
            continue

        qa_pairs = multihop_qa.get("qa_pairs", [])
        if not qa_pairs:
            print("è·³è¿‡ï¼ˆæ— qa_pairsï¼‰")
            continue

        print(f"æ‰¾åˆ° {len(qa_pairs)} ä¸ªQAå¯¹")
        processed_items += 1

        for qa in qa_pairs:
            if not isinstance(qa, dict):
                continue

            question = qa.get("question", "").strip()
            answer_text = qa.get("answer", "").strip()

            # è·³è¿‡ç©ºé—®é¢˜æˆ–ç­”æ¡ˆ
            if not question or not answer_text:
                continue

            # åˆå¹¶æ¨ç†æ­¥éª¤
            reasoning_steps = qa.get("reasoning_steps", [])
            reasoning_text = "\n".join(
                [step.get("step", "").strip() for step in reasoning_steps if
                 isinstance(step, dict) and step.get("step", "").strip()])

            # æ„å»ºè¾“å‡ºï¼ˆæ¨ç†è¿‡ç¨‹ + ç­”æ¡ˆï¼‰
            if reasoning_text:
                output_text = f"{reasoning_text}\n\n{answer_text}"
            else:
                output_text = answer_text

            results.append({
                "instruction": instruction,
                "input": question,
                "output": output_text
            })

            total_qa_pairs += 1

    print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"æ€»æ•°æ®é¡¹: {len(data)}")
    print(f"æœ‰æ•ˆé¡¹ç›®: {processed_items}")
    print(f"è½¬æ¢QAå¯¹: {total_qa_pairs}")

    if not results:
        print("âŒ æ²¡æœ‰è½¬æ¢ä»»ä½•QAå¯¹ï¼è¯·æ£€æŸ¥æ•°æ®æ ¼å¼")

        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ•°æ®é¡¹çš„ç»“æ„ä¾›è°ƒè¯•
        if data and isinstance(data[0], dict):
            print("ğŸ“‹ ç¬¬ä¸€ä¸ªæ•°æ®é¡¹çš„ç»“æ„:")
            print(json.dumps(data[0], indent=2, ensure_ascii=False)[:500] + "...")

        return None

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜ä¸ºqa.jsonï¼ˆLlamaFactoryæ ‡å‡†æ ¼å¼ï¼‰
    qa_file = output_dir / "qa.json"
    try:
        with open(qa_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        file_size = qa_file.stat().st_size
        print(f"âœ… è½¬æ¢å®Œæˆ: {len(results)} ä¸ªQAå¯¹ -> {qa_file} ({file_size} å­—èŠ‚)")

        return qa_file
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return None


def create_llamafactory_config(output_dir=None):
    """Create dataset_info.json for LlamaFactory"""
    script_dir = get_script_dir()

    if output_dir is None:
        output_dir = script_dir / "data"
    else:
        output_dir = Path(output_dir)

    print("ğŸ“‹ åˆ›å»ºLlamaFactoryé…ç½®...")

    # LlamaFactory dataset configuration
    dataset_info = {
        "kb_qa": {
            "file_name": "qa.json",
            "columns": {
                "prompt": "instruction",
                "query": "input",
                "response": "output"
            }
        }
    }

    config_file = output_dir / "dataset_info.json"
    try:
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, ensure_ascii=False, indent=2)

        print(f"âœ… LlamaFactoryé…ç½®åˆ›å»º: {config_file}")
        print(f"æ•°æ®é›†åç§°: kb_qa")
        return config_file
    except Exception as e:
        print(f"âŒ åˆ›å»ºé…ç½®å¤±è´¥: {e}")
        return None


def verify_output(output_dir=None):
    """éªŒè¯è¾“å‡ºæ–‡ä»¶"""
    script_dir = get_script_dir()

    if output_dir is None:
        output_dir = script_dir / "data"
    else:
        output_dir = Path(output_dir)

    print(f"\nğŸ” éªŒè¯è¾“å‡ºæ–‡ä»¶ (ç›®å½•: {output_dir})...")

    qa_file = output_dir / "qa.json"
    config_file = output_dir / "dataset_info.json"

    # æ£€æŸ¥qa.json
    if qa_file.exists():
        size = qa_file.stat().st_size
        print(f"âœ… qa.json: {size} å­—èŠ‚")

        try:
            with open(qa_file, 'r', encoding='utf-8') as f:
                qa_data = json.load(f)
            print(f"âœ… qa.jsonåŒ…å« {len(qa_data)} ä¸ªæ ·æœ¬")

            if qa_data:
                sample = qa_data[0]
                print(f"ğŸ“‹ æ ·æœ¬å­—æ®µ: {list(sample.keys())}")
        except Exception as e:
            print(f"âŒ qa.jsonéªŒè¯å¤±è´¥: {e}")
    else:
        print(f"âŒ æœªæ‰¾åˆ° qa.json")

    # æ£€æŸ¥dataset_info.json
    if config_file.exists():
        print(f"âœ… dataset_info.json å­˜åœ¨")
    else:
        print(f"âŒ æœªæ‰¾åˆ° dataset_info.json")


if __name__ == "__main__":
    print("ğŸš€ QAæ•°æ®è½¬æ¢å·¥å…·ï¼ˆç›¸å¯¹è·¯å¾„ç‰ˆï¼‰")
    print("=" * 50)

    script_dir = get_script_dir()
    print(f"ğŸ“‚ è„šæœ¬æ‰€åœ¨ç›®å½•: {script_dir}")

    # æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶ï¼ˆç›¸å¯¹äºè„šæœ¬ä½ç½®ï¼‰
    input_file = find_input_file()
    if not input_file:
        print("\nğŸ’¡ æç¤ºï¼š")
        print("1. ç¡®ä¿å·²è¿è¡Œ Pdf2QAPipeline.py")
        print("2. æ£€æŸ¥ .cache/gpu/ ç›®å½•æ˜¯å¦å­˜åœ¨")
        print("3. å¦‚æœæ–‡ä»¶åœ¨å…¶ä»–ä½ç½®ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šè·¯å¾„")
        exit(1)

    # è¾“å‡ºç›®å½•ï¼ˆç›¸å¯¹äºè„šæœ¬ä½ç½®ï¼‰
    output_dir = script_dir / "data"

    print(f"\nå¼€å§‹è½¬æ¢...")
    print(f"è¾“å…¥: {input_file}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("-" * 50)

    # Convert data
    qa_file = convert_to_alpaca(input_file, output_dir)

    if qa_file:
        # Create config file
        config_file = create_llamafactory_config(output_dir)

        if config_file:
            print(f"\nğŸ‰ æ•°æ®è½¬æ¢å®Œæˆ!")
            verify_output(output_dir)

            print(f"\nç°åœ¨å¯ä»¥è¿è¡Œè®­ç»ƒ:")
            print(f"python LlamaFactory.py --dry-run  # é¢„è§ˆ")
            print(f"python LlamaFactory.py           # å®é™…è®­ç»ƒ")
        else:
            print("âŒ é…ç½®æ–‡ä»¶åˆ›å»ºå¤±è´¥")
    else:
        print("âŒ æ•°æ®è½¬æ¢å¤±è´¥")

    print(f"\nğŸ“‚ æ‰€æœ‰è·¯å¾„éƒ½ç›¸å¯¹äºè„šæœ¬ä½ç½®: {script_dir}")