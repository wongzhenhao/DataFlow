# operator_writer_ui_gradio.py  ---- Gradio ç‰ˆ UI
"""
å¯åŠ¨æ–¹æ³•  
-------------
1. å®‰è£…ä¾èµ–  
   pip install -U gradio requests sseclient-py

2. è¿è¡Œ  
   python operator_writer_ui_gradio.py

3. æµè§ˆå™¨è®¿é—®  
   http://localhost:7860
"""
import json, os, requests, contextlib
from typing import Dict, Any, Generator, Tuple

import gradio as gr
from sseclient import SSEClient  # ä»…ç”¨äºè§£æåç«¯ /stream æ¥å£çš„ Server-Sent Events


# ============ å·¥å…·å‡½æ•° ============
def build_payload(
    language: str,
    target: str,
    model: str,
    session_key: str,
    json_file: str,
    py_path: str,
    api_key: str,
    chat_api: str,
    execute_operator: bool,
    use_local_model: bool,
    local_model: str,
    timeout: int,
    max_debug: int,
) -> Dict[str, Any]:
    return {
        "language": language,
        "target": target,
        "model": model,
        "sessionKEY": session_key,
        "json_file": json_file,
        "py_path": py_path,
        "api_key": api_key,
        "chat_api_url": chat_api,
        "execute_the_operator": execute_operator,
        "use_local_model": use_local_model,
        "local_model_name_or_path": local_model,
        "timeout": timeout,
        "max_debug_round": max_debug,
    }


def get_latest_operator_file(py_path: str) -> Tuple[str, str]:
    """
    åœ¨ `py_path` çš„ä¸Šçº§ç›®å½•ä¸­ï¼Œæ‰¾å‡ºåç§°åŒ…å«åŸºå‡†åä¸”ä»¥ .py ç»“å°¾çš„æœ€æ–°æ–‡ä»¶ã€‚
    è¿”å› (æ–‡ä»¶ç»å¯¹è·¯å¾„, æ–‡ä»¶å†…å®¹)ã€‚å¤±è´¥è¿”å› ("", "")ã€‚
    """
    dir_path = os.path.dirname(py_path)
    if not dir_path:
        return "", ""

    base_name = os.path.splitext(os.path.basename(py_path))[0]

    try:
        candidates = [
            f for f in os.listdir(dir_path)
            if f.endswith(".py") and base_name in f
        ]
    except FileNotFoundError:
        return "", ""

    if not candidates:
        return "", ""

    full_paths = [os.path.join(dir_path, f) for f in candidates]
    latest_file = max(full_paths, key=os.path.getmtime)

    with contextlib.suppress(Exception):
        with open(latest_file, "r", encoding="utf-8") as fp:
            return latest_file, fp.read()

    return "", ""


def read_cache_local(cache_dir: str = "./cache_local") -> dict:
    """
    è¯»å– cache_local ç›®å½•ä¸‹å…¨éƒ¨ .json / .jsonl æ–‡ä»¶å¹¶è¿”å› dictã€‚
    ç»“æ„: {filename: data}
    """
    if not os.path.isdir(cache_dir):
        return {}

    cache_data = {}
    for fn in os.listdir(cache_dir):
        if not (fn.endswith(".json") or fn.endswith(".jsonl")):
            continue
        path = os.path.join(cache_dir, fn)
        try:
            with open(path, "r", encoding="utf-8") as f:
                if fn.endswith(".json"):
                    cache_data[fn] = json.load(f)
                else:  # jsonl
                    cache_data[fn] = [json.loads(line) for line in f if line.strip()]
        except Exception as e:
            cache_data[fn] = f"<è¯»å–å¤±è´¥: {e}>"
    return cache_data


# ------------- æ™®é€šè¯·æ±‚ -------------
def normal_request(
    api_base: str,
    language: str,
    model: str,
    session_key: str,
    target: str,
    json_file: str,
    py_path: str,
    api_key: str,
    chat_api: str,
    execute_operator: bool,
    use_local_model: bool,
    local_model: str,
    timeout: int,
    max_debug: int,
) -> Tuple[str, dict]:
    payload = build_payload(
        language, target, model, session_key,
        json_file, py_path, api_key, chat_api,
        execute_operator, use_local_model, local_model,
        timeout, max_debug,
    )
    try:
        r = requests.post(f"{api_base}/chatagent", json=payload, timeout=timeout + 30)
        if r.ok:
            return f"âœ… HTTP {r.status_code}", r.json()
        else:
            return f"âŒ HTTP {r.status_code}: {r.text}", {}
    except Exception as e:
        return f"âŒ å¼‚å¸¸: {e}", {}


# ---------- æµå¼è¯·æ±‚ ----------
def stream_request(
    api_base: str,
    language: str,
    model: str,
    session_key: str,
    target: str,
    json_file: str,
    py_path: str,
    api_key: str,
    chat_api: str,
    execute_operator: bool,
    use_local_model: bool,
    local_model: str,
    timeout: int,
    max_debug: int,
) -> Generator[Tuple[str, str, dict], None, None]:
    """
    Gradio generatorï¼šå®æ—¶ yield (æ—¥å¿—, ä»£ç , cache_local æ•°æ®)ã€‚
    """
    payload = build_payload(
        language, target, model, session_key,
        json_file, py_path, api_key, chat_api,
        execute_operator, use_local_model, local_model,
        timeout, max_debug,
    )

    whole_log, code_text, cache_data = "", "", {}
    try:
        resp = requests.post(
            f"{api_base}/chatagent/stream",
            json=payload,
            stream=True,
            timeout=None,
        )
        if resp.status_code != 200:
            yield f"âŒ {resp.status_code}: {resp.text}", code_text, cache_data
            return

        for raw in resp.iter_lines(decode_unicode=True):
            if not raw:
                continue
            if raw.startswith("data: "):
                data = json.loads(raw[6:])
                evt = data.get("event")

                if evt == "connected":
                    line = f"ğŸ”— è¿æ¥å»ºç«‹: {data.get('message')}"
                elif evt == "start":
                    line = f"ğŸ›  å¼€å§‹ä»»åŠ¡ `{data['task']}` â€¦"
                elif evt == "ping":
                    line = f"â³ {data.get('message')}"
                elif evt == "finish":
                    line = (
                        f"âœ… `ä»»åŠ¡ï¼š{data['task']}` å®Œæˆï¼Œç”¨æ—¶ {data['elapsed']} ç§’\n"
                        f"ç»“æœ:\n{json.dumps(data['result'], ensure_ascii=False, indent=2)}"
                    )
                elif evt == "done":
                    line = "ğŸ‰ å…¨éƒ¨ä»»åŠ¡å®Œæˆ"

                    # è¯»å–æœ€æ–°ç®—å­æ–‡ä»¶
                    fp, content = get_latest_operator_file(py_path)
                    if content:
                        code_text = f"# æ–‡ä»¶: {fp}\n\n{content}"

                    # å¦‚æ‰§è¡Œäº†ç®—å­ï¼Œåˆ™è¯»å– cache_local
                    if execute_operator:
                        cache_data = read_cache_local()
                elif evt == "error":
                    line = f"âŒ å‡ºé”™: {data['detail']}"
                else:
                    line = f"{data}"

                whole_log += line + "\n\n"
                yield whole_log, code_text, cache_data

        yield whole_log, code_text, cache_data

    except Exception as e:
        yield whole_log + f"\nâŒ æµå¼è¯·æ±‚å¼‚å¸¸: {e}", code_text, cache_data


# ============ Gradio UI ============
with gr.Blocks(title="DataFlow-Agent Â· å†™ç®—å­ (Gradio)") as demo:
    gr.Markdown("## ğŸ› ï¸ DataFlow-Agent Â· å†™ç®—å­ (Operator Writer)")

    with gr.Row():
        api_base = gr.Textbox(label="åç«¯åœ°å€", value="http://localhost:8000")
        language = gr.Dropdown(["zh", "en"], value="zh", label="Language")
        model    = gr.Textbox(label="LLM Model", value="deepseek-v3")

    session_key = gr.Textbox(label="sessionKEY(ä¼šè¯å”¯ä¸€æ ‡è¯†)", value="dataflow_demo")
    target = gr.Textbox(
        label="ç›®æ ‡ï¼ˆTargetï¼‰", lines=4,
        value="æˆ‘éœ€è¦ä¸€ä¸ªç®—å­ï¼Œèƒ½å¤Ÿå¯¹æ•°æ®è¿›è¡Œæƒ…æ„Ÿåˆ†æå¹¶è¾“å‡ºç§¯æ/æ¶ˆææ ‡ç­¾ã€‚"
    )

    gr.Markdown("---")

    json_file = gr.Textbox(label="å¾…å¤„ç†çš„JSONæ–‡ä»¶åœ°å€",
        value="")
    py_path = gr.Textbox(label="ç®—å­ä»£ç ä¿å­˜è·¯å¾„",
        value="")
    api_key = gr.Textbox(label="DF_API_KEY", type="password",
        value="")
    chat_api = gr.Textbox(label="DF_API_URL",
        value="")

    with gr.Row():
        execute_operator = gr.Checkbox(label="æ‰§è¡Œç®—å­", value=False)
        use_local_model  = gr.Checkbox(label="ä½¿ç”¨æœ¬åœ°æ¨¡å‹", value=False)

    local_model = gr.Textbox(label="æœ¬åœ°æ¨¡å‹è·¯å¾„",
        value="/mnt/public/model/huggingface/Qwen2.5-7B-Instruct")

    with gr.Row():
        timeout   = gr.Slider(60, 7200, value=3600, step=60, label="è¶…æ—¶ (s)")
        max_debug = gr.Slider(1, 20, value=5, step=1, label="æœ€å¤§ Debug è½®æ•°")

    # ---------- æ™®é€šè¯·æ±‚ ----------
    gr.Markdown("### ğŸ“® æ™®é€šè¯·æ±‚ï¼ˆç›´æ¥è¿”å›æœ€ç»ˆæ‰§è¡Œç»“æœï¼‰")
    normal_btn  = gr.Button("å‘é€")
    norm_status = gr.Textbox(label="çŠ¶æ€")
    norm_output = gr.JSON(label="è¿”å›ç»“æœ")

    # ---------- æµå¼è¯·æ±‚ ----------
    gr.Markdown("### ğŸš€ æµå¼è¯·æ±‚ï¼ˆå¯è§†åŒ–agentå¤„ç†è¿‡ç¨‹ï¼‰")
    stream_btn  = gr.Button("å¼€å§‹æµå¼")
    stream_box  = gr.Textbox(lines=20, label="æµå¼è¾“å‡º", interactive=False)
    code_box    = gr.Code(label="ç”Ÿæˆçš„ç®—å­ä»£ç  (py)", language="python", lines=22)
    cache_box   = gr.JSON(label="cache_local ç®—å­å¤„ç†ä¹‹åçš„æ•°æ®å†…å®¹")

    # äº‹ä»¶ç»‘å®š
    normal_btn.click(
        fn=normal_request,
        inputs=[api_base, language, model, session_key, target,
                json_file, py_path, api_key, chat_api,
                execute_operator, use_local_model, local_model,
                timeout, max_debug],
        outputs=[norm_status, norm_output],
    )

    stream_btn.click(
        fn=stream_request,
        inputs=[api_base, language, model, session_key, target,
                json_file, py_path, api_key, chat_api,
                execute_operator, use_local_model, local_model,
                timeout, max_debug],
        outputs=[stream_box, code_box, cache_box],
    )


# ---------- å¯åŠ¨ ----------
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)